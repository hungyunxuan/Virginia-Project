# -*- coding: utf-8 -*-
"""ML4VA 2024.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-fgidTv3y5CAEA6mXSPdjbVbQgvKvOpp
"""

import pandas as pd
#TODO: change this when in colab
dataset = pd.read_csv("sample_data/Social_Vulnerability_Index.csv")

"""# Dataset exploration"""

dataset.info()

incomplete_rows = dataset[dataset.isnull().any(axis=1)]
incomplete_rows

dataset.describe()

dataset["E_POV"].describe()

dataset["EP_POV"].describe()

#Correlational matrix
#Label column: E_POV (Persons below poverty estimate, 2014-2018 ACS)

#Correlational matrix
pd.set_option('display.max_rows', 500)
corr_matrix = dataset.corr(numeric_only=True)
corr_matrix["E_POV"].sort_values(ascending=False)

#plotting correlation matrices
from pandas.plotting import scatter_matrix
#Scatter matrix of some attributes from housing data
attributes = ["E_POV", "E_NOVEH", "E_SNGPNT", "E_NOHSDP", "E_UNINSUR", "E_DISABL"]

scatter_matrix(dataset[attributes], figsize=(12, 8))

"""# Data preprocessing

## data pre-processing steps:
- prune dataframe
  - input: dataframe
  - output: dataframe with just the relevant columns and rows
- optionally, split the pruned dataset into train and test sets
  - input: cleaned dataframe, label for y column
  - output: X_train, y_train, X_test, y_test
- scale input data for optional use
"""

# clean dataset, removing margin of error (MOE) columns and rows with undesirable values (0 population, negative income, etc.)
# returns: cleaned dataset dataframe
def prune_df(df):
    # remove MOE columns
    moe_col_prefixes = ("M_", "MP_")
    moe_cols = [col for col in df.columns if any(col.startswith(col_prefix) for col_prefix in moe_col_prefixes)]
    df = df.drop(columns=moe_cols)

    # remove column "the_geom", which i think describes the shape of a tract
    # not currently sure what to do with a MultiPolygon either
    df = df.drop(columns="the_geom")

    # remove census tracts with no inhabitants
    df = df[df["E_TOTPOP"] != 0]

    # remove labels of particular census tracts from input data
    # as they aren't features of a particular census tract
    df = df.drop(columns=["ST", "STATE", "ST_ABBR", "STCNTY", "COUNTY", "FIPS", "LOCATION"])

    return df

from sklearn.model_selection import train_test_split
def split_train_test(dataset):

  # splitting dataset into train (80%) and test (20%) sets
  train_set, test_set = train_test_split(dataset, test_size=0.2, random_state=7)

  X_train = train_set.copy()
  X_test = test_set.copy()
  # attributes columns
  # filter based on like col.endswith("POV")
  for col in (c for c in dataset.columns if c.endswith("POV")):
    X_train = X_train.drop(col, axis=1)
    X_test = X_test.drop(col, axis=1)
  # gets labels
  y_train = train_set["EP_POV"].copy()
  y_test = test_set["EP_POV"].copy()

  return X_train, y_train, X_test, y_test

from sklearn.metrics import mean_absolute_error, mean_squared_error
def print_metrics(y_true, y_pred):
    print(f"MAE: {mean_absolute_error(y_true, y_pred)}")
    print(f"RMSE: {mean_squared_error(y_true, y_pred, squared=False)}")

# likely used universally
from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.preprocessing import StandardScaler

preprocessing_pipeline = make_pipeline(StandardScaler())

dataset_pruned = prune_df(dataset)
X_train, y_train, X_test, y_test = split_train_test(dataset_pruned)
X_train_tr = preprocessing_pipeline.fit_transform(X_train)
X_test_tr = preprocessing_pipeline.transform(X_test)

"""# Experiments"""

#Linear Regression
import numpy as np
from sklearn.linear_model import LinearRegression
linear_regressor = LinearRegression()
linear_regressor.fit(X_train_tr, y_train)
Y_pred = linear_regressor.predict(X_test_tr)
#print(Y_pred) #length = 376


#evaluating the linear regression model
lin_mse = mean_squared_error(y_test, Y_pred)
lin_rmse = np.sqrt(lin_mse)
lin_rmse
#lin_rmse = 4.652329050353858
from sklearn.metrics import mean_absolute_error

lin_mae = mean_absolute_error(y_test, Y_pred)
lin_mae #2.6743197066000923

#Logistic Regression
#According to the US Census Bureau, the official poverty rate in 2022 was 11.5%, the areas with
#EP_POV > 11.5 would be considered 1 for below poverty line and 0 for above poverty line
import numpy as np
dataset_pruned = prune_df(dataset)
#print(dataset_pruned.columns.get_loc("EP_POV")) -> EP_POV is still inside the dataset
train_set, test_set = train_test_split(dataset_pruned, test_size=0.2, random_state=7)
X_train = train_set.copy()
X_test = test_set.copy()
#print(X_train.columns.get_loc("EP_POV")) -> EP_POV is still inside the dataset
#print(X_train["EP_POV"].mean()) -> 7.646675531914893
#print(X_train["EP_POV"].std()) -> 64.5598531568897
X_train['Log_result'] = np.where ((X_train['EP_POV'] > 11.5), 1, 0)
for col in (c for c in dataset_pruned.columns if c.endswith("POV")):
  X_train = X_train.drop(col, axis=1)
  X_test = X_test.drop(col, axis=1)
#print(X_train.shape) -> correct number of cols
y_train = train_set["EP_POV"].copy()
y_test = test_set["EP_POV"].copy()
y_test_tr = np.where ((y_test> 11.5), 1, 0)
preprocessing_pipeline = make_pipeline(StandardScaler())

X_train_without_results = X_train.drop(columns=['Log_result'])
X_train_tr = preprocessing_pipeline.fit_transform(X_train_without_results)
results = X_train["Log_result"].values.tolist()
#print(results) -> results is in a list form
#print(X_train_tr.shape)
#print(len(results)) -> the results list is of equal length that of X_train_tr

y_train_tr = results
#X_train_tr_with_lg = np.column_stack((X_train_tr, results))
#print(X_train_tr_with_lg[:,-1]) -> produces the correct output
X_test_tr = preprocessing_pipeline.transform(X_test)
#print(X_test_tr.shape) -> correct shape

from sklearn.linear_model import LogisticRegression
logreg = LogisticRegression(random_state=42)
logreg.fit(X_train_tr, y_train_tr)
y_pred = logreg.predict(X_test)

#evaluating logistic regression
from sklearn import metrics
cnf_matrix = metrics.confusion_matrix(y_test_tr, y_pred)
cnf_matrix

#confusion matrix evaluation metrics
from sklearn.metrics import classification_report
target_names = ['not in poverty', 'in poverty']
print(classification_report(y_test_tr, y_pred, target_names=target_names))

#roc curve
import matplotlib.pyplot as plt
y_pred_proba = logreg.predict_proba(X_test_tr)[::,1]
fpr, tpr, _ = metrics.roc_curve(y_test_tr,  y_pred_proba)
auc = metrics.roc_auc_score(y_test_tr, y_pred_proba)
plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
plt.legend(loc=4)
plt.show()

#rmse
lin_mse = mean_squared_error(y_test, y_pred)
lin_rmse = np.sqrt(lin_mse)
lin_rmse
#17.558824386324595

#mae
lin_mae = mean_absolute_error(y_test, y_pred)
#lin_mae #13.018351063829787

"""## SVM Regression"""

from sklearn.svm import SVR, LinearSVR
from sklearn.model_selection import GridSearchCV

# no longer used; full scale of tested parameters
base_param_grid = {
    'C': [.1, 1, 10, 100, 1000, 10_000, 50_000, 100_000, 1_000_000, 10_000_000],
    'gamma': ['scale', 'auto', 1e-5, .0001, .001, .01, .1, 1]
}

# kernel-specific parameter grids
# search spaces have been narrowed for more efficient grid-search iteration
kernel_param_grids = {
    'linear': {
        'C': [.1, 1, 10, 100, 1000],
    },
    'poly': {
        'C': [.1, 1, 10, 100],
        'degree': [2, 3, 4, 5],
        'gamma': ['scale', 'auto', .001, .01],
    },
    'rbf': {
        # 'C': [10_000, 50_000, 100_000, 1_000_000],
        # 'gamma': ['scale', 'auto', 1e-5, .0001, .001, .01, .1, 1]
        'C': [1_000_000],
        'gamma': [1e-6, 1e-5, 1e-4],
    }
}


def grid_search_helper(estimator, param_grid):
    search = GridSearchCV(estimator, param_grid=param_grid, n_jobs=-1)
    search.fit(X_train_tr, y_train)
    return search

# map kernels to GridSearchCV objects for hyper-param tuning
best_svr_per_kernel = {}

# curious if any particular kernel outperforms others

for k, params in kernel_param_grids.items():
    if k == "linear":
        estimator = LinearSVR(dual=True)
        param_grid = params
    else:
        estimator = SVR()
        param_grid = {'kernel': [k]} | params

    search = grid_search_helper(estimator, param_grid)

    print(f"\nkernel: {k}")
    print("Best parameter (CV score=%0.3f):" % search.best_score_)
    print(f"{search.best_params_=}")

    # search.best_estimator_ has been fit using the input training data, using the best params
    best_svr_per_kernel[k] = search

# best_svr_search = max(best_svr_per_kernel.values(), key=lambda search: search.best_score_)

# print("Best parameter (CV score=%0.3f):" % best_svr_search.best_score_)
# print(f"{best_svr_search.best_params_=}")

best_svr = SVR(kernel='rbf', C=1_000_000, gamma=1e-5)
best_svr.fit(X_train_tr, y_train)

y_pred = best_svr.predict(X_test_tr)
print_metrics(y_test, y_pred)

"""## Random Forest regression"""

from sklearn.ensemble import RandomForestRegressor

param_grid = {
    "max_features": ["sqrt", "log2", None, .1, .3, .8],
    "n_estimators": [10, 50, 100, 150, 200, 250],
}

# search = grid_search_helper(RandomForestRegressor(random_state=7), param_grid)

# print(f"{search.best_score_=}")
# print(f"{search.best_params_=}")

# best_rfr = search.best_estimator_
best_rfr = RandomForestRegressor(n_estimators=10, max_features=0.3, random_state=7)
best_rfr.fit(X_train_tr, y_train)

y_pred = best_rfr.predict(X_test_tr)
print_metrics(y_test, y_pred)

fi = best_rfr.feature_importances_
sorted(zip(fi, X_train.columns), reverse=True)

"""for context, the 3 most important impurity-based features for this particular estimator are:
1. Percentile percentage of persons in group quarters estimate
2. Percentage of civilian noninstitutionalized population with a disability estimate, 2014-2018 ACS
3. Percentile percentage households with no vehicle available estimate

saved info at time of running:
```
search.best_score_=0.8706929875138698
search.best_params_={'max_features': 0.3, 'n_estimators': 10}
MAE: 3.578244680851064
RMSE: 5.579681938239391
```

# KMeans
"""